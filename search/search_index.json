{"config":{"lang":["de"],"separator":"[\\s]","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Willkommen auf der Elasticsearch Dokumentation","text":"<p>Dieses Dokument/Seite soll Informationen f\u00fcr das Arbeiten mit Elasticsearch bereitstellen.  Es sollen Anleitungen, Use Cases, Erkl\u00e4rungen und Best Practices gesammelt werden. </p> <p>Diese Seite wird laufend aktualisiert.</p>"},{"location":"Installation/01_installation_one_node/","title":"Installation Elasticsearch - One Node Cluster","text":""},{"location":"Installation/01_installation_one_node/#umgebung","title":"Umgebung:","text":"<p>Link:                    https://www.elastic.co/guide/en/elasticsearch/reference/current/rpm.html OS:                      Centos Stream 9 Virtualisierung:   vSphere Server A:             Elasticsearch, Kibana Server B:             Logstash, Filebeat, Python Scripts Voraussetzung:   JAVA JDK Version</p>"},{"location":"Installation/01_installation_one_node/#server-a","title":"Server A","text":""},{"location":"Installation/01_installation_one_node/#elasticsearch-installation","title":"Elasticsearch Installation","text":"<p>Per Repo-Einbindung Elastic installieren:</p> <p><pre><code>cd /etc/yum.repos.d/\nsudo vim elasticsearch.repo\n</code></pre> Info: Repo sollte f\u00fcr alle drei Komponenten ausreichen (Elastic, Filebeat, Kibana) <pre><code>[elasticsearch]\nname=Elastic repository for 8.x packages\nbaseurl=https://artifacts.elastic.co/packages/8.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n</code></pre></p> <pre><code>Optional (nur unter RHEL9): update-crypto-policies --set DEFAULT:SHA1\nsudo dnf install --enablerepo=elasticsearch elasticsearch\nsystemctl daemon-reload\nsystemctl enable elasticsearch\nsystemctl start elasticsearch\nfirewall-cmd --add-port=9200/tcp --permanent\nfirewall-cmd --reload\n</code></pre> <p>Lesson learned = Es wird ein elastic (Superuser) Passwort nach der Installation im Terminal ausgegeben. Das Passwort ist wichtig f\u00fcr den Zugang zu Elasticsearch. Also am besten speichern. Elasticsearch gibt in der Doku an, das Passwort in eine Umgebungsvariable zu speichern. Erscheint mir unsicher, aber f\u00fcr lokale Instanzen zum ausprobieren sollte es okay sein.  In Elasticsearch 8+ sind die Sicherheitseinstellungen an. Das bedeutet, dass in der elasticsearch.yml mehr Optionen in der eingetragen werden m\u00fcssen als die initiale Doku zeigt. Lesson learned = Entweder \u00fcber eine .repo Datei oder \u00fcber ein wget die Installation erm\u00f6glichen</p> <p>Konfiguration <pre><code>sudo vim /etc/elasticsearch/elasticsearch.yml\n</code></pre></p> <p>Entferne die # vor den Eintr\u00e4gen:     network.host: localhost  Zus\u00e4tzlich m\u00fcssen noch die Pfade f\u00fcr xpack.security.http und xpack.security.transport gesetzt werden. <pre><code>    #-------------------------------Node------------------\n    node.name: localhost\n\n\n    # Set the bind address to a specific IP (IPv4 or IPv6): \n     network.host: localhost \n    #\n    # Set a custom port for HTTP: \n     http.port: 9200                                               # Muss nicht unbedingt gesetzt werden, da der Default 9300 ist.\n    # elasticsearch.host: [\"http://localhost:9200\"]\n\n    # --------------------------------- Discovery ----------------------------------\n    #\n    # Pass an initial list of hosts to perform discovery when this node is started:\n    # The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n    #\n    discovery.seed_hosts: [\"127.0.0.1\"]\n    #\n    # Bootstrap the cluster using an initial set of master-eligible nodes:\n    #\n    #----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------\n    #\n    # The following settings, TLS certificates, and keys have been automatically      \n    # generated to configure Elasticsearch security features on 28-08-2023 14:32:16\n    #\n    # --------------------------------------------------------------------------------\n\n    # Enable security features\n\n    xpack.security.enabled: true\n    xpack.security.enrollment.enabled: true\n\n    # Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents\n    xpack.security.http.ssl:\n      enabled: true\n      keystore.path: /etc/elasticsearch/certs/http.p12\n\n    # Enable encryption and mutual authentication between cluster nodes\n    xpack.security.transport.ssl:\n      enabled: true\n      verification_mode: certificate\n      keystore.path: /etc/elasticsearch/certs/transport.p12\n      truststore.path: /etc/elasticsearch/certs/certs/transport.p12\n    # Create a new cluster with the current node only\n    # Additional nodes can still join the cluster later\n    cluster.initial_master_nodes: [\"localhost.localdomain\"]\n</code></pre></p> <p>Das bei der Installation erschaffenene Zertifikat muss noch per <code>scp</code> an den Server B (auf dem Logstash installiert wird) kopiert werden und in dem Ordner hinterlegt werden, der in der <code>logstash.yml</code> angegeben ist. </p> <p>Keystore  (Muss ich mir noch genauer Anschauen) <pre><code>Nur wenn unter /etc/elasticsearch/ noch nicht enthalten ist:\n/usr/share/elasticsearch/bin/elasticsearch-keystore create\n\nPasswort immer neu setzen:\n/usr/share/elasticsearch/bin/elasticsearch-keystore passwd\n\nPasswort f\u00fcr den Http.Keystore abfragen. Dies ist f\u00fcr die Konfiguration von Logstash wichtig.\n/usr/share/elasticsearch/bin/elasticsearch-keystore show xpack.security.http.ssl.keystore.secure_password\n</code></pre></p> <p>Um eine CA zu erstellen, muss folgender Befehl eingegeben werden:</p> <pre><code>Erstellt eine CA:\n/usr/share/elasticsearch/bin/elasticsearch-certutil ca\n\nErstellt ein Cert(braucht man aber bei einem Server nicht, da Initial Certs mitkommen):\n/usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12\n</code></pre> <p>Lesson learned: In Elastic 8 oder neu wird SSL im Default aktiviert</p> <p>Der Server muss dann rebootet werden.</p>"},{"location":"Installation/01_installation_one_node/#kibana-installation","title":"Kibana Installation","text":"<p>Kibana Repo unter <code>/etc/yum.repos.d/kibana.repo</code> anlegen.</p> <pre><code>sudo dnf install kibana\n</code></pre> <p>Konfiguration <pre><code>sudo vim /etc/kibana/kibana.yml\n</code></pre></p> <p>Entferne die # vor den Eintr\u00e4gen: <pre><code>server.port: 5601\nserver.host: \"localhost\"                          # Alternative hier eine IP Addresse ohne \"\" eintragen\nelasticsearch.hosts: [\"https://localhost:9200\"]\n</code></pre></p> <pre><code>systemctl start kibana\nsystemctl enable kibana\n\nfirewall-cmd --add-port=5601/tcp --permanent\nfirewall-cmd --reload\n</code></pre> <p>Einen Enrollment-Token f\u00fcr Kibana erstellen: <pre><code>/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token --scope kibana\n</code></pre> Den Token auf \"localhost:5601\" im Browser eingeben. Auf dem Server einen Verifizierungs-Code erstellen und im Browser eingeben:</p> <pre><code>/usr/share/kibana/bin/kibana-verification-code\n</code></pre>"},{"location":"Installation/01_installation_one_node/#server-a_1","title":"Server A","text":""},{"location":"Installation/01_installation_one_node/#install-logstash","title":"Install Logstash","text":""},{"location":"Installation/01_installation_one_node/#user-anlegen","title":"User anlegen:","text":"<p>In Kibana (auf Server A) muss unter Management -&gt; Dev Tools per API ein User <code>logstash_writer</code> und die Rolle <code>logstash_writer_role</code> erstellt werden.</p> <pre><code>POST /_security/role/logstash_write_role\n{\n    \"cluster\": [\n      \"monitor\",\n      \"manage_index_templates\"\n    ],\n    \"indices\": [\n      {\n        \"names\": [\n           \"filebeat*\"\n        ],\n        \"privileges\": [\n          \"write\",\n          \"create_index\"\n        ],\n        \"field_security\": {\n          \"grant\": [\n            \"*\"\n          ]\n        }\n      }\n    ],\n    \"run_as\": [],\n    \"metadata\": {},\n    \"transient_metadata\": {\n      \"enabled\": true\n    }\n}\n\nPOST /_security/user/logstash_writer\n{\n  \"username\": \"logstash_writer\",\n  \"roles\": [\n    \"logstash_write_role\"\n  ],\n  \"full_name\": null,\n  \"email\": null,\n  \"password\": \"PASSWORD\",\n  \"enabled\": true\n}\n</code></pre> <p>Mit <code>/user/share/elasticsearch/bin/elasticsearch_reset_password -u logstash_writer</code> muss das Passwort neu gesetzt werden und dann per Dev Tools in Kibana gesetzt werden.</p>"},{"location":"Installation/01_installation_one_node/#zertifikate-ubertragen","title":"Zertifikate \u00fcbertragen","text":"<p>\u00dcbertragung des Zertifikats per <pre><code>scp path/to/http_ca.crt user@IP:/home/user\n</code></pre></p> <p>\u00dcbertragung des SSL-Keys per  <pre><code>scp path/to/http.p12 user@IP:/home/user\n</code></pre></p>"},{"location":"Installation/01_installation_one_node/#server-b","title":"Server B","text":"<p>Installation Installation von Logstash auf dem Server.</p> <p><pre><code>vim /etc/yum.repos.d/logstash.repo\n</code></pre> Repo-Datei: logstash.repo <pre><code>[logstash-8.x]\nname=Elastic repository for 8.x packages\nbaseurl=https://artifacts.elastic.co/packages/8.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n</code></pre> Logstash \u00fcber die Kommandozeile installieren und Zertifikate in ein Verzeichnis ablegen. Zus\u00e4tzlich m\u00fcssen dann die User/Group Berechtigungen von root auf logstash ge\u00e4ndert werden, damit Logstash die Zertifikate finden und nutzen kann. <pre><code># Installation\ndnf install logstash\n\n# Erstellung des Ordners f\u00fcr die Zertifikate und der Kopiervorgang\nmkdir /etc/logstash/certs\ncp /home/user/http* /etc/logstash/certs/\n\n# \u00c4nderung der Rechte\nchown -R logstash:logstash /etc/logstash/\n</code></pre> Konfiguration Die Konfigurations-Datei von Logstash bearbeiten <pre><code>vim /etc/logstash/logstash.yml\n</code></pre> Entscheidend sind die X-Pack bzw SSL -Einstellungen: (F\u00fcr den logstash_system User muss entweder das Passwort auf dem Elasticserver neu generiert werden oder man kennt es schon) <pre><code># X-Pack Management\nxpack.management.enabled: true\nxpack.management.elasticsearch.username: logstash_system\nxpack.management.elasticsearch.password: 'PASSWORD'\nxpack.management.elasticsearch.hosts: \"https://IP:9200\"\nxpack.management.elasticsearch.ssl.certificate_authority: \"/etc/logstash/certs/http_ca.crt\"\nxpack.management.elasticsearch.ssl.certificate: \"/etc/logstash/certs/http_ca.crt\"\nxpack.management.elasticsearch.ssl.key: \"/etc/logstash/certs/http.p12\"\n</code></pre></p> <p>Es muss eine Konfigurationsdatei f\u00fcr die Pipeline von Filebeat -&gt; Logstash -&gt; Elasticsearch konfiguriert werden. <pre><code>vim /etc/logstash/conf.d/logstash.conf\n</code></pre> Lesson learned: Die Conf-Dateien m\u00fcssen unter conf.d stehen Lesson learned: SSL ist bei Logstash auch ein \"Problem\". <pre><code>input {\n  beats {\n     port =&gt; 5044\n     }\n}\n\nfilter {    #&lt;---- Hier kann der Filter definiert werden\n  grok {\n    match =&gt; {}\n  }\n  date {\n    match =&gt; []\n    target =&gt; \"\"\n  }\n}\n\noutput {\n  elasticsearch {\n    hosts =&gt; [\"https://IP:9200\"]\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}\"\n    cacert =&gt; '/etc/logstash/certs/http_ca_crt'    #&lt;--- Kann nat\u00fcrlich Variable sein\n    user =&gt; \"logstash_writer\"\n    password =&gt; \"PASSWORD\"\n    ssl =&gt; true\n  }\n}\n</code></pre></p> <p>Konfig testen: /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf --config.test_and_exit</p>"},{"location":"Installation/01_installation_one_node/#install-filebeat","title":"Install Filebeat","text":"<p>Installation Stelle sicher, dass Kibana l\u00e4uft</p> <p><pre><code>dnf install filebeat\n\nsudo filebeat modules enable system\n\nvim /etc/filebeat/filebeat.yml\n</code></pre> Die filebeat.yml ist die Konfig-Datei f\u00fcr Filebeat.</p> <p>Konfiguration Auf jeder Maschine muss eine Filebeat/Beat Konfigurationsdatei angelegt werden.  <pre><code>...\n#----------------Filebeat Input--------------------\nfilebeat.inputs:\n- type: log   #Hier wird ein Typ angegeben\n  enabled: true\n  paths:      #Hier werden die Pfade zu den Daten angeben\n    - /var/log/*.log\n\n#--------------------Logstash Output--------------------\noutput.logstash\n  hosts: [\"localhost:5044\"]\n</code></pre></p> <p>M\u00f6chte man Module nutzen, m\u00fcssen diese per <code>filebeat module enable MODULNAME</code> angeschaltet werden. Die Module liegen unter /etc/filebeat/modules. Das Kommando benennt die Datei von MODULNAME-disabled.yml in MODULNAME.yml</p> <pre><code>/usr/share/filebeat/bin/filebeat -e -c /etc/filebeat/filebeat.yml -d \"publish\"\n</code></pre>"},{"location":"Installation/02_1_Installation_three_node_cluster/","title":"installation Elasticsearch - Three Node CLuster","text":""},{"location":"Installation/02_1_Installation_three_node_cluster/#umgebung","title":"Umgebung:","text":"<p>Link:                    https://www.elastic.co/guide/en/elasticsearch/reference/current/rpm.html OS:                      Centos Stream 9 Virtualisierung:   vSphere Server A:             Elasticsearch Server B:             Elasticsearch Server C:             Elasticsearch Server D:             Kibana Voraussetzung:   JAVA JDK Version</p>"},{"location":"Installation/02_1_Installation_three_node_cluster/#server-a","title":"Server A","text":""},{"location":"Installation/02_1_Installation_three_node_cluster/#elasticsearch-installation","title":"Elasticsearch Installation","text":"<p>Per Repo-Einbindung Elastic installieren:</p> <p><pre><code>cd /etc/yum.repos.d/\nsudo vim elasticsearch.repo\n</code></pre> Info: Repo sollte f\u00fcr alle drei Komponenten ausreichen (Elastic, Filebeat, Kibana) <pre><code>[elasticsearch]\nname=Elastic repository for 8.x packages\nbaseurl=https://artifacts.elastic.co/packages/8.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n</code></pre></p> <pre><code>Optional (nur unter RHEL9): update-crypto-policies --set DEFAULT:SHA1\nsudo dnf install --enablerepo=elasticsearch elasticsearch\nsystemctl daemon-reload\nsystemctl enable elasticsearch\nsystemctl start elasticsearch\nfirewall-cmd --add-port=9200/tcp --permanent\nfirewall-cmd --reload\n</code></pre> <p>Lesson learned = Es wird ein elastic (Superuser) Passwort nach der Installation im Terminal ausgegeben. Das Passwort ist wichtig f\u00fcr den Zugang zu Elasticsearch. Also am besten speichern. Elasticsearch gibt in der Doku an, das Passwort in eine Umgebungsvariable zu speichern. Erscheint mir unsicher, aber f\u00fcr lokale Instanzen zum ausprobieren sollte es okay sein.  In Elasticsearch 8+ sind die Sicherheitseinstellungen an. Das bedeutet, dass in der elasticsearch.yml mehr Optionen in der eingetragen werden m\u00fcssen als die initiale Doku zeigt. Lesson learned = Entweder \u00fcber eine .repo Datei oder \u00fcber ein wget die Installation erm\u00f6glichen</p> <p>Konfiguration <pre><code>sudo vim /etc/elasticsearch/elasticsearch.yml\n</code></pre></p> <pre><code>    #-------------------------------Node------------------\n    node.name: localhost\n\n\n    # Set the bind address to a specific IP (IPv4 or IPv6): \n     network.host: localhost \n    #\n    # Set a custom port for HTTP: \n     http.port: 9200\n    # elasticsearch.host: [\"http://localhost:9200\"]\n\n    # --------------------------------- Discovery ----------------------------------\n    #\n    # Pass an initial list of hosts to perform discovery when this node is started:\n    # The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n    #\n    discovery.seed_hosts: [\"127.0.0.1\"]\n    #\n    # Bootstrap the cluster using an initial set of master-eligible nodes:\n    #\n    #----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------\n    #\n    # The following settings, TLS certificates, and keys have been automatically      \n    # generated to configure Elasticsearch security features on 28-08-2023 14:32:16\n    #\n    # --------------------------------------------------------------------------------\n\n    # Enable security features\n\n    xpack.security.enabled: true\n    xpack.security.enrollment.enabled: true\n\n    # Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents\n    xpack.security.http.ssl:\n      enabled: true\n      keystore.path: /etc/elasticsearch/certs/http.p12\n\n    # Enable encryption and mutual authentication between cluster nodes\n    xpack.security.transport.ssl:\n      enabled: true\n      verification_mode: certificate\n      keystore.path: /etc/elasticsearch/certs/transport.p12\n      truststore.path: /etc/elasticsearch/certs/certs/transport.p12\n    # Create a new cluster with the current node only\n    # Additional nodes can still join the cluster later\n    cluster.initial_master_nodes: [\"localhost.localdomain\"]                         # Wenn DNS genutzt werden soll/wird, muss hier der FQDN des Servers stehen\n</code></pre> <p>Das bei der Installation erschaffenene Zertifikat muss noch per <code>scp</code> an den Server B (auf dem Logstash installiert wird) kopiert werden und in dem Ordner hinterlegt werden, der in der <code>logstash.yml</code> angegeben ist. </p> <p>Lesson learned: Wenn man DNS nutzt, dann muss unter <code>cluster.initial_master_nodes</code> ein FQDN eingetragen werden. Probleme kann es geben, wenn der Name nachtr\u00e4glich angepasst wird, nachdem man Elastic installiert hat, da dann die Zertifikate falsch sind.</p> <p>Keystore  (Muss ich mir noch genauer Anschauen) <pre><code>Nur wenn unter /etc/elasticsearch/ noch nicht enthalten ist:\n/usr/share/elasticsearch/bin/elasticsearch-keystore create\n\nPasswort immer neu setzen:\n/usr/share/elasticsearch/bin/elasticsearch-keystore passwd\n\nPasswort anzeigen lassen\n/usr/share/elasticsearch/bin/elasticsearch-keystore show xpack.security.http.ssl.keystore.secure_password\n</code></pre></p> <p>Um eine CA zu erstellen, muss folgender Befehl eingegeben werden:</p> <pre><code>Erstellt eine CA:\n/usr/share/elasticsearch/bin/elasticsearch-certutil ca\n\nErstellt ein Cert(braucht man aber bei einem Server nicht, da Initial Certs mitkommen):\n/usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12\n</code></pre> <p>Lesson learned: In Elastic 8 oder neu wird SSL im Default aktiviert</p> <p>Der Server muss dann rebootet werden.</p>"},{"location":"Installation/02_1_Installation_three_node_cluster/#kibana-installation","title":"Kibana Installation","text":"<p>Kibana Repo unter <code>/etc/yum.repos.d/kibana.repo</code> anlegen.</p> <pre><code>sudo dnf install kibana\n</code></pre> <p>Konfiguration <pre><code>sudo vim /etc/kibana/kibana.yml\n</code></pre></p> <p>Entferne die # vor den Eintr\u00e4gen: <pre><code>server.port: 5601\nserver.host: \"localhost\"                          # Alternative hier eine IP Addresse ohne \"\" eintragen\nelasticsearch.hosts: [\"https://localhost:9200\"]\n</code></pre></p> <pre><code>systemctl start kibana\nsystemctl enable kibana\n\nfirewall-cmd --add-port=5601/tcp --permanent\nfirewall-cmd --reload\n</code></pre> <p>Einen Enrollment-Token f\u00fcr Kibana erstellen: <pre><code>/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token --scope kibana\n</code></pre> Den Token auf \"localhost:5601\" im Browser eingeben. Auf dem Server einen Verifizierungs-Code erstellen und im Browser eingeben:</p> <pre><code>/usr/share/kibana/bin/kibana-verification-code\n</code></pre>"},{"location":"Installation/02_1_Installation_three_node_cluster/#server-a_1","title":"Server A","text":""},{"location":"Installation/02_1_Installation_three_node_cluster/#install-logstash","title":"Install Logstash","text":"<p>User anlegen: In Kibana (auf Server A) muss unter Management -&gt; Dev Tools per API ein User <code>logstash_writer</code> und die Rolle <code>logstash_writer_role</code> erstellt werden.</p> <pre><code>POST /_security/user/role/logstash_write_role\n{\n    \"cluster\": [\n      \"monitor\",\n      \"manage_index_templates\"\n    ],\n    \"indices\": [\n      {\n        \"names\": [\n           \"filebeat*\"\n        ],\n        \"privileges\": [\n          \"write\",\n          \"create_index\"\n        ],\n        \"field_security\": {\n          \"grant\": [\n            \"*\"\n          ]\n        }\n      }\n    ],\n    \"run_as\": [],\n    \"metadata\": {},\n    \"transient_metadata\": {\n      \"enabled\": true\n    }\n}\n\nPOST /_security/user/logstash_writer\n{\n  \"username\": \"logstash_writer\",\n  \"roles\" [\n    \"logstash_write_role\"\n  ],\n  \"full_name\": null,\n  \"email\": null\n  \"password\": \"PASSWORD\"\n  \"enabled\": true\n}\n</code></pre> <p>Mit <code>/user/share/elasticsearch/bin/elasticsearch_reset_password -u logstash_writer</code> muss das Passwort neu gesetzt werden und dann per Dev Tools in Kibana gesetzt werden.</p> <p>Zertifikate \u00fcbertragen \u00dcbertragung des Zertifikats per <code>scp path/to/http_ca.crt user@IP:/home/user \u00dcbertragung des SSL-Keys per</code>scp path/to/http.p12 user@IP:/home/user</p>"},{"location":"Installation/02_1_Installation_three_node_cluster/#server-b","title":"Server B","text":"<p>Installation Installation von Logstash auf dem Server.</p> <p><pre><code>vim /etc/yum.repos.d/logstash.repo\n</code></pre> Repo-Datei: logstash.repo <pre><code>[logstash-8.x]\nname=Elastic repository for 8.x packages\nbaseurl=https://artifacts.elastic.co/packages/8.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n</code></pre> Logstash \u00fcber die Kommandozeile installieren und Zertifikate in ein Verzeichnis ablegen. Zus\u00e4tzlich m\u00fcssen dann die User/Group Berechtigungen von root auf logstash ge\u00e4ndert werden, damit Logstash die Zertifikate finden und nutzen kann. <pre><code># Installation\ndnf install logstash\n\n# Erstellung des Ordners f\u00fcr die Zertifikate und der Kopiervorgang\nmkdir /etc/logstash/certs\ncp /home/user/http* /etc/logstash/certs/\n\n# \u00c4nderung der Rechte\nchown -R logstash:logstash /etc/logstash/\n</code></pre> Konfiguration Die Konfigurations-Datei von Logstash bearbeiten <pre><code>vim /etc/logstash/logstash.yml\n</code></pre> Entscheidend sind die X-Pack bzw SSL -Einstellungen: (F\u00fcr den logstash_system User muss entweder das Passwort auf dem Elasticserver neu generiert werden oder man kennt es schon) <pre><code># X-Pack Management\nxpack.management.enabled: true\nxpack.management.elasticsearch.username: logstash_system\nxpack.management.elasticsearch.password: 'PASSWORD'\nxpack.management.elasticsearch.hosts: \"https://IP:9200\"\nxpack.management.elasticsearch.ssl.certificate_authority: \"/etc/logstash/certs/http_ca.crt\"\nxpack.management.elasticsearch.ssl.keystore.path: \"/etc/logstash/certs/http.p12\"\nxpack.management.elasticsearch.ssl.keystore.password: 'PASSOWRD'\n#xpack.management.elasticsearch.ssl.certificate: \"/etc/logstash/certs/http_ca.crt\"\n#xpack.management.elasticsearch.ssl.key: \"/etc/logstash/certs/http.p12\"\n</code></pre></p> <p>Es muss eine Konfigurationsdatei f\u00fcr die Pipeline von Filebeat -&gt; Logstash -&gt; Elasticsearch konfiguriert werden. <pre><code>vim /etc/logstash/conf.d/logstash.conf\n</code></pre> Lesson learned: Die Conf-Dateien m\u00fcssen unter conf.d stehen Lesson learned: SSL ist bei Logstash auch ein \"Problem\".  Es scheint so zu sein, dass man die verschl\u00fcsselt .p12 Files sind. Man kann das keystore-Passwort auf den Elasticsearch-Maschinen abfragen. <pre><code>input {\n  beats {\n     port =&gt; 5044\n     }\n}\n\nfilter {    #&lt;---- Hier kann der Filter definiert werden\n  grok {\n    match =&gt; {}\n  }\n  date {\n    match =&gt; []\n    target =&gt; \"\"\n  }\n}\n\noutput {\n  elasticsearch {\n    hosts =&gt; [\"https://IP:9200\"]\n    index =&gt; \"%{[@metadata][beat]}-%{[@metadata][version]}\"\n    cacert =&gt; '/etc/logstash/certs/http_ca_crt'    #&lt;--- Kann nat\u00fcrlich Variable sein\n    user =&gt; \"logstash_writer\"\n    password =&gt; \"PASSWORD\"\n    ssl =&gt; true\n  }\n}\n</code></pre></p>"},{"location":"Installation/02_1_Installation_three_node_cluster/#install-filebeat","title":"Install Filebeat","text":"<p>Installation Stelle sicher, dass Kibana l\u00e4uft</p> <p><pre><code>dnf install filebeat\n\nsudo filebeat modules enable system\n\nvim /etc/filebeat/filebeat.yml\n</code></pre> Die filebeat.yml ist die Konfig-Datei f\u00fcr Filebeat.</p> <p>Konfiguration Auf jeder Maschine muss eine Filebeat/Beat Konfigurationsdatei angelegt werden.  <pre><code>...\n#----------------Filebeat Input--------------------\nfilebeat.inputs:\n- type: log   #Hier wird ein Typ angegeben\n  enabled: true\n  paths:      #Hier werden die Pfade zu den Daten angeben\n    - /var/log/*.log\n\n#--------------------Logstash Output--------------------\noutput.logstash\n  hosts: [\"localhost:5044\"]\n</code></pre></p> <p>M\u00f6chte man Module nutzen, m\u00fcssen diese per <code>filebeat module enable MODULNAME</code> angeschaltet werden. Die Module liegen unter /etc/filebeat/modules. Das Kommando benennt die Datei von MODULNAME-disabled.yml in MODULNAME.yml</p>"}]}